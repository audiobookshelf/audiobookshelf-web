---
title: Using The API & Advanced Server Management
slug: using-the-api
fullpath: /guides/using-the-api
---

---

# Table of Contents
- [# Updating Chapters](#updating-chapters) (And [# Repairing Chapters with Audacity](#audacity-chapter-workflow))
- [# Get Your Reading History](#get-your-reading-history) (And [# Importing With Goodreads](#goodreads-importing))
- [# Encode Books as M4B](#encode-book-as-m4b)
---

# Introduction

To use the API a few things are required. 
- The url to your current ABS instance and usually which library you wish to interact with. 
- An API Key which you can get from the Users page by **clicking on the User** not the edit button or via the [Login](https://api.audiobookshelf.org/#login) endpoint
![User Token](/guides/using_the_api/user.jpg)
- Command specific data in JSON form

> ℹ️ For any `GET` commands if you are logged into the server in a browser you can navigate to the api url for testing/small jobs

## The API Docs

While not automatically kept up to date the API Docs show most everything you can do with your ABS server. The current iteration of them can be found [here](https://api.audiobookshelf.org). If you wish to dig deeper, watch the network calls while navigating your ABS server from inside a browser (F12 > Network by default in many browsers).

When using the docs pay attention to the sections linked under the command of interest as they show exactly what ABS is expecting from more complex parameters.
![Example Parameters](/guides/using_the_api/example_parameters.jpg)

## A Note About Curl

> ℹ️ Depending on if you are running on Linux or Windows your commands will look slightly different.
- Multi-line commands are ended with `^` on Windows and `\` on Linux
- Linux strings can be 'in single quotes' while Windows strings must "be in double quotes"
  - This means Windows strings, ie. JSON, containing quotes must have their quotes escaped as `\"`
- You dont usually need to specify `-X POST` or `-X GET`, examples include it for clarity

Windows CMD 
```cmd
curl -X POST http://localhost:13378/audiobookshelf/api/items/{bookID}/chapters ^
  -H "Authorization: Bearer user.api.token.here" ^
  -H "Content-Type: application/json" ^
  -d "{\"chapters\": [{\"id\":0,\"start\":0,\"end\":150.296003,\"title\":\"Introduction\"}]}"
```

Linux Bash
```bash
curl -X POST http://localhost:13378/audiobookshelf/api/items/{bookID}/chapters \
  -H "Authorization: Bearer user.api.token.here" \
  -H "Content-Type: application/json" \
  -d '{"chapters": [{"id":0,"start":0,"end":150.296003,"title":"Introduction"}]}'
```

---
# Updating Chapters
Chapters can be batch updated via JSON, this is useful for books that are recombined from parts that have been split on seperated CDs or downloaded as parts and thus dont match up with the chapter data that might be available elsewhere.

> ⚠️ Be aware that this has to be ALL the chapters together since this endpoint overwrites whatever chapter data is currently there.

### Required Info
- **Item ID** - From the URL of the book in question <ins>your.ABS.intance/audiobookshelf/item/**dc385e6a-693b-4daa-823f-1f8f70c0c63a**</ins>
- **API Token** - From the Users page by **clicking on the User** not the edit button or via the [Login](https://api.audiobookshelf.org/#login) endpoint
- **Chapters** - The data in JSON format `{"chapters": [{"id":0,"start":0,"end":150,"title":"Introduction"}] }`

---

# Audacity Chapter Workflow

Using audacity we can streamline the process of adding chapters to a book that has unusable/no chapter markers.
1. Use the audio label tool to auto detect chapters
    - Clean up extra or missing chapter markers
2. Export those labels and turn them into the format ABS expects from api calls
    - From TSV to an array of JSON objects
3. Post our data to the ABS server

> ℹ️ To navigate Labels use Alt+ArrowKeys to jump between them and Shift+Scroll to scroll audio left and right

## Label Chapters in Audacity
- Select a ~12h segment - Audacity cannot process more than 13.5h of 44khz audio at a time with the label tool.
- Analyze > Label Sounds
  ![Analyze Settings](/guides/using_the_api/audacity_analyze.jpg)
- A good place to start is `Minimum Silence: 3s` plus `Minimum Label Interval: 1s`
  - You might have to play with the settings a little based on how slow the narrators speak or how tightly the editting is done
  - You can highlight the silence before a chapter marker to get a guess of how long of a silence you need
  - Change the Label Text to `Chapter ##1` to automatically name the chapters and avoid having to rename them later
- If a chapter is missing select the overly long section by clicking the label for it
  - Right Click the Label > Delete Label
  - Reanalyze the highlighted section with more forgiving settings 2.5 or lower works well to split chapters
  - Clean up labels
- Edit > Labels > Edit Labels > Export

### Alternatively Edit Preexisting Chapters
If you have access to the metadata files, use [the item endpoint](https://api.audiobookshelf.org/#get-a-library-item), or just change `/audiobookshelf/item/8d1ce4...` to `/api`/item`s`/8d1ce4... in your browser you can get the chapter data that ABS already has so you can clean it up yourself. Audacity expects TSV data in the form of `start  end title` in a text file. You can convert the ABS json to TSV using [this site](https://codebeautify.org/json-to-tsv-converter) or your favorite tool.
- Chapters can be imported as label data
  - Edit > Labels > Edit Labels...
  - Import > Select your .txt file and ignore the warning if you didnt string the id column out, its fine
    ![Example Labels](/guides/using_the_api/labels.jpg)
  - Drag the circles between chapter markers to place the end/beginnings in the correct place
- Sometimes chapter markers past a certain point are all offset from their audio
  - This is common when books were chopped up to fit on CDs
  - You can select all chapters past your marker using `Shift+End`
    - Do this only on the chapter track not the audio! (Shift+LClick the label track header to clear selected audio)
  - `Ctrl+X` to cut and then paste the labels to line up the chapter and all subsequent ones
  |LClick to Select Chapter|Shift+LClick Track Head to DeSelect Audio|Shift+End to Select Remaining Chapters|
  |:--|:--|:--|
  |![Select Chapter](/guides/using_the_api/000.png)|![Only Labels](/guides/using_the_api/001.png)|![Select to End](/guides/using_the_api/002.png)|

  |Ctrl+X to Cut Chapters|Alt+Left Arrow to Jump to Last Chapter|Ctrl+V to Paste Chapters at New Location|
  |:--|:--|:--|
  |![Select Chapter](/guides/using_the_api/003.png)|![Only Labels](/guides/using_the_api/004.png)|![Select to End](/guides/using_the_api/005.png)|
  - You will probably have to do this as many times as there were disks originally
- Remember to Export your labels when you are done
  - Edit > Labels > Edit Lables > Export

## Add missing ID column to TSV
First we need to add the chapter ids to our exported data
- Paste labels into a spreadsheet and add column headers and an id column starting at 0
- Export as TSV or CSV
- Ensure column headers are [`id,start,end,title`]
    ![Example Labels](/guides/using_the_api/TSV.jpg)
Instead you can also use your text editor of choice if it is feature rich, just remember to add the column headers before converting to JSON
  - [Here](https://numbergenerator.org/numberlist#!low=0&high=200&csv=nl&oddeven=&step=1&addfilters=) is a convenient number list tool for ids


## Convert TSV to JSON
- [This](https://csvjson.com/csv2json) converter is convenient and also is a cli tool if that fits your workflow better.
- Also available as an npm package https://www.npmjs.com/package/csvjson-csv2json
- Output: Array > Minify   Make sure these settings are selected so things don't interfere with cURL later 
    ![Converter Settings](/guides/using_the_api/converter_settings.jpg)

## cURL command to update chapters
This is where we use the api key from earlier along with our book's item id
- JSON payload must be {chapters: [array of chapter objects]}
- For windows the json payload needs to have its `"`s escapted as `\"` since cmd doesn't like single quotes
- Dont forget to close the curly bracket after pasting in the converted json array

Windows CMD - Remember to replace `"`s with `\"`s in the big array
```cmd
-d "{\"chapters\": [that big json array]}"
```

Linux Bash
```bash
-d '{"chapters": [that big json array]}'
```

If the book has many chapters you might have to save the chapter data as a json file and curl the file instead
 - Just remember to run the command from where your json is saved or use its filepath

```cmd
-d @"chapters.json"
```

---
# Get Your Reading History

## Required Info
- **API Token** - From the Users page by **clicking on the User** not the edit button or via the [Login](https://api.audiobookshelf.org/#login) endpoint
- **User ID** - From user page URL <ins>/audiobookshelf/config/users/**47a2c8c7-0404-4365-bb83-fb14e2b00744**</ins>

> ℹ️ The `/api/users/userID` endpoint requires an admin API key but the `/api/me` endpoint does not

## Pulling your data
<details>
<summary>ℹ️ <ins>Here is a sample script to pull reading history and export a Goodreads csv</ins></summary>

```python
# Pull all reading progress from the /me endpoint and store as a file
# Look up every item to pull full book data
# Export as Goodreads csv

# TO USE:
# Paste URL to the ABS server in ABS_HOST
# Paste your api key in the API_KEY - Login to website and look for `Authorization: Bearer {your key}` in your browser's network tab
# -H and -k flags overwrite hardcoded values
# -p pulls reading data again even in progress.json exists
# -t runs like normal but does not write any values

import json
import os
import requests
import argparse

###### Configuration #####

ABS_HOST = "http://localhost:13378"
API_KEY = ""

#########################

if args.host:
    ABS_HOST = args.host

if args.key:
    API_KEY = args.key

ME_URI = "/api/me"
USER_URI = "/api/user/"
ITEM_URI = "/api/items/"

AUTH = f"token={API_KEY}"
# Some way to do metadata-object path too?

parser = argparse.ArgumentParser()

parser.add_argument("-H","--host", action='store',help="ABS host, overwrites hardcoded host.")
parser.add_argument("-k","--key", action='store',help="API key, overwrites hardcoded key.")
parser.add_argument("-p", "--pull", action='store_true',help="Pull new reading history from the host.")
parser.add_argument("-t", "--test", action='store_true',help="Run script but do not do any file manipulation.")
args = parser.parse_args()

##### Methods #####

def pullProgress():
    print("Pulling progress data")
    me = requests.get(f"{ABS_HOST}{ME_URI}?token={API_KEY}")
    print(me.reason)


    books = []

    for pObject in me.json()["mediaProgress"]:
        book = {}
        book["progress"] = pObject
        books.append(book)

    print("Pulling book info")

    for book in books:
        req = requests.get(f"{ABS_HOST}{ITEM_URI}{book["progress"]["libraryItemId"]}?{AUTH}")
        print(req.reason)
        info = req.json()
        if req.ok:
            book.update(info)

    with open("progress.json","w") as f:
        if not args.test: 
            f.write(json.dumps(books))
        f.close()
    
    print("Done pulling reading history")

## Export Types ##

def goodreadsCSV():
    print("Writing to CSV compatible with GoodReads")
    # Title, Author, Additional Authors(, seperated list), ISBN, Publisher, Binding?(Audiobook), Year Published, Bookshelves, Bookshelves with positions? (Collections)
    books = []

    with open("progress.json","r") as js:
        books = json.load(js)
        js.close()
    
    with open("toGoodreads.csv","w") as csv:
        headers = ["Title", "Author", "Additional Authors", "ISBN", "Publisher", "Year Published", "Binding"]

        if not args.test:
            csv.writelines(','.join(f'"{w}"' for w in headers)+'\n')
        
        for b in books:
            
            Title = ""
            Authors = []
            Narrators = []
            ISBN = ""
            Publisher = ""
            Published = ""
            Binding = ""
            Tags = ""

            Title = b["media"]["metadata"]["title"]
            for a in b["media"]["metadata"]["authors"]:
                Authors.append(a["name"])
            
            Narrators = b["media"]["metadata"]["narrators"]
            ISBN = b["media"]["metadata"]["isbn"]
            Publisher = b["media"]["metadata"]["publisher"]
            Published = b["media"]["metadata"]["publishedYear"]
            Binding = "Audiobook" if b["progress"]["progress"] != 0 and b["progress"]["ebookProgress"] == 0 else ""

            values = []
            values.append(Title)
            values.append(Authors[0])
            values.append(f"{','.join(Authors[1:]+Narrators)}")
            values.append(ISBN)
            values.append(Publisher)
            values.append(Published)
            values.append(Binding)

            if not args.test:
                csv.writelines(','.join(f'"{v.replace('"',"'") if v else ""}"' for v in values)+"\n")

        csv.close()

if args.pull or not os.path.isfile("progress.json"):
    pullProgress()

goodreadsCSV()
```

</details>

Either use the [user endpoint](https://api.audiobookshelf.org/#get-a-user) or navigate to in a browser to `/audiobookshelf/api/users/{userID}`. Alternatively if you are interested in your own data you can use the `/audiobookshelf/api/me` [endpoint](https://api.audiobookshelf.org/#get-your-user) or url.

Each book the user has read has a corresponding mediaProgress object:
```json
{
  "id": "c1413395-a9a6-4632-9556-01fb2czca400",             //The ID of the internal Progress Record
  "userId": "9be14cdb-22zz-4445-9191-d1h54523529708",       //The ID of the User
  "libraryItemId": "9141ba3a-ce32-5bdd-9432-4d6af425160d",  //The ID of the Book used in URLs
  "episodeId": null,                                        //The ID of the Podcast Episode if podcast
  "mediaItemId": "b3enbaf6-fvb0-4v7c-bfsb-29rw51364a68",    //The ID of the internal book/podcast file
  "mediaItemType": "book",                                  //Is it a book or podcastEpisode
  "duration": 77192.973333,                                 //How long the book is
  "progress": 1,                                            //How far the user read as a fraction (0-1)
  "currentTime": 77192.978,                                 //Where the user ended
  "isFinished": true,                                       //Was it auto or manually Mark as Finished
  "hideFromContinueListening": false,                       //Did the user hide this item on the homepage
  "ebookLocation": "epubcfi(/6/18!/4/2/278/1:0)",           //Ebook style progress location
  "ebookProgress": 0.2397,                                  //Ebook progress as a fraction (0-1)
  "lastUpdate": 1735409116524,                              //Unix Epoch timestamp 
  "startedAt": 1734152810867,                               //Unix Epoch timestamp 
  "finishedAt": 1735409116524,                              //Unix Epoch timestamp 
  "displayTitle": "The Black Prism",                        //Book/Podcast Episode Title
  "displaySubtitle": "Only used for Podcasts",              //Podcast Name
  "coverPath": "T:/he/path_to/your_cover_art.jpg",          //Filesystem path to cover art
  "mediaUpdatedAt": "2022-05-11T01:51:17.931Z"              //
}
```

> ⚠️ As of <ins>v2.24.0</ins> the `/api/me` endpoint does not return the `displayTitle` or `displaySubtitle`. Use the `/api/users/{userID}` endpoint if this is all you need or look up `libraryItemId` seperately from the `/api/items/{itemID}` [endpoint](https://api.audiobookshelf.org/#get-a-library-item) or `/api/items/{itemID}/metadata-object`.

## Converting to ISBN
Many popular book tracking sites will only let you import books by their ISBN and you may have to do a look-up depending on what metadata is in your ABS server.

Audnex.us is used by ABS and often times will have an ISBN in their book [endpoint](https://audnex.us/#tag/Books/operation/getBookById) `api.audnex.us/books/{ASIN}`

We can use the ABS search [endpoint](https://api.audiobookshelf.org/#search-for-books) as well with to get results containing an ISBN.

At this point the call chain is `/api/me` or `/api/users/{userID}` → `/api/items/{bookID}` or `/api/items/{bookID}/metadata-object` → ISBN with an optional `/api/search/books` if the server doesn't already have it. Now we are ready for importing into most 3rd party services.

> ℹ️ The ASIN can be used in the title parameter though sanity checking that there is a description or publisher is a good way to toss out [strange results](localhost:13378/api/search/books?title=B002VA3LF8&author=Diana%20Gabaldon)


## Goodreads Importing
Since 2020 Goodreads has shuttered their API access and now only allows importing books through their Import/Export portal. To do this you need an ISBN for any book you want to import though it allows many other optional data points as well.

The most basic import can be just a .txt file or web page with ISBNs which Goodreads will try to match with books in its database. Goodreads has many editions of books but definitely *not* all books! This is where supplying more information as a .csv or .xls will allow Goodreads to try and search for the book instead of the specific edition that an ISBN represents.

For a more advanced import you may format your reading history as an .xls or .csv file with at least an ISBN column. Extra optional columns include: Title, Author, My Rating, Average Rating, Publisher, Binding, Year Published, Original Publication Year, Date Read, Date Added,Shelves, Bookshelves, My Review

By default imported books will be placed in the `read` shelf unless otherwise specified in a `Bookshelves` column. Other default options are `to-read` and `currently-reading`. Shelves are Goodreads equivilent to tags and should be treated as such with the 3 default ones being mutually exclusive. Spaces in existing tags should be replaced by dashes as Goodreads treats the `Bookshelves` entry as a list of space seperated tags.

> ⚠️ Any entry that has a comma in it should be surrounded by double quotes. (ie. Titles and Reviews)

The importer works at ~100 titles every 5 minutes so if you are importing a larger collection it may take a while. You should be ok to import books you already have in your collection though be aware that if you include ratings or reviews they will be overwritten when you import a second time. If you refresh the imports page you will get an running list of books that have/haven't been imported and details on problem titles.
![import](/guides/using_the_api/live_update.png)

For books being imported without an ISBN there is a good chance that Goodreads has chosen a book that is almost but not quite what you intended. If you use the small search bar in your My Books section you can find a lot of common missidentified books. Try:
- "Study" or "Study Guide" (Often the author is BookRags)
- "Summary" (Sample or SparkNotes style overviews often by InstaRead)
- "Art" or "The Art of" (Artbooks for popular series)
- "Articles" (Collated works all kinds of text about popular books/authors by Hephaestus Books)
- "Conversation" (Conversation starters by Daily Books)
- "Box" or "Collection" (Bundle deals)
- "Free" or "Sample"

> ℹ️ Sometimes books will be imported in other languages as well but there is currently not a good way to filter for it.

## The Storygraph Importing
Storygraph's only import option is to read a Goodreads export csv. It must have the exact same columns and order as a Goodreads export and is only intended to be done once. Any duplicate entries will also be duplicated on Storygraph and must be remedied by hand.

[todo]: <> (## Library Thing)
[todo]: <> (ISBNs, TSV Import might work, Crazy custom JSON - Export test data and reImport)


[todo]: <> (## Hardcover)
[todo]: <> (Popular social reading app.)

---
# Encode Book as M4B
This tool is accessable from Edit > Tools page for each book but [this endpoint](https://api.audiobookshelf.org/#encode-a-book-as-m4b) allows automation

## Required Info
- **ADMIN API Token** - From the Users page by **clicking on the User** not the edit button or via the [Login](https://api.audiobookshelf.org/#login) endpoint
- **Item ID** - From item page URL <ins>/audiobookshelf/item/**e81d2966-a948-4ecd-a3e4-d262492cf51d**</ins>

When choosing the bitrate/codec/channel count for this command its useful to know what the current audio files stats are. Using the [library item endpoint](https://api.audiobookshelf.org/#get-a-library-item) or changing `/audiobookshelf/item/e8ba45c0-9d34-4e7a-8f5b-439e41eca731` to /audiobookshelf/`api/`item`s`/e8ba45c0-9d34-4e7a-8f5b-439e41eca731 you can inspect the `audioFiles > bitRate/codec/channels`

As far as codecs go most of the time you can just use the `copy` setting to avoid transcoding the audio unless you want specifically to change it. People have reported issues with playing M4B files that still have an mp3 audio codec in other programs especially ones that assume it will be handling an `aac` codec. In such cases you can reuse the command with a new codec (`acc` or `opus` lowercase)

Multiple commands can be started in parallel but be some users have had issues with starting too many at once. It is dependant on the hardware you have hosting your ABS server. Start slowly and figure out what your server can handle.
- If you queue too many commands you can substitute `-X DELETE` for `-X POST` with the same command to cancel encoding for that specific book

> ⚠️ Be aware that these commands move the old audio files to the metadata/cache/items folder and must be cleared out periodically. Use [this](https://api.audiobookshelf.org/#purge-items-cache) endpoint or if convenient delete the local files.

[todo]: <> (---)
[todo]: <> (# Uploading Ebooks For Already Existing Audiobooks)

[todo]: <> (<folderDir>/<author>/<series>/<title>)
[todo]: <> (<libraryFolder>/<author>/<series>/<title>)
[todo]: <> (  -F library="0309d2a8-20ff-4ca6-a724-3b8e1831ef40" ^ ID of the parent Library as seen in URLs)
[todo]: <> (  -F folder="35d48d04-aec1-40dc-b3fb-5d88013285f3"^  ID from the libraries endpoint - Libraries can pull from multiple media folders)
[todo]: <> (https://api.audiobookshelf.org/#upload-files)
